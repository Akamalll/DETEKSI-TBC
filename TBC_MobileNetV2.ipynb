{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
            "DATA_DIR: D:\\SKRIPSI\\DETEKSI TBC\\DATASET\n",
            "TensorFlow: 2.20.0\n"
          ]
        }
      ],
      "source": [
        "# Setup: versi, path, dan import dasar\n",
        "import sys, os\n",
        "print(\"Python:\", sys.version)\n",
        "\n",
        "# Path dataset\n",
        "BASE_DIR = r\"D:\\SKRIPSI\\DETEKSI TBC\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"DATASET\")\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "\n",
        "# Install dependensi di dalam notebook (aman di Jupyter)\n",
        "try:\n",
        "\timport tensorflow as tf\n",
        "except ModuleNotFoundError:\n",
        "\timport sys\n",
        "\t!{sys.executable} -m pip install tensorflow\n",
        "\timport tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3035 images belonging to 2 classes.\n",
            "Found 758 images belonging to 2 classes.\n",
            "Classes: {'normal': 0, 'tuberculosis': 1}\n",
            "steps_per_epoch: 94 validation_steps: 23\n"
          ]
        }
      ],
      "source": [
        "# Parameter data & split\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "VAL_SPLIT = 0.2\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "\tpreprocessing_function=preprocess_input,\n",
        "\trotation_range=10,\n",
        "\twidth_shift_range=0.05,\n",
        "\theight_shift_range=0.05,\n",
        "\tzoom_range=0.1,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode='nearest',\n",
        "\tvalidation_split=VAL_SPLIT,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "\tpreprocessing_function=preprocess_input,\n",
        "\tvalidation_split=VAL_SPLIT,\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "\tDATA_DIR,\n",
        "\ttarget_size=IMG_SIZE,\n",
        "\tbatch_size=BATCH_SIZE,\n",
        "\tclass_mode='binary',\n",
        "\tsubset='training',\n",
        "\tseed=SEED,\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "\tDATA_DIR,\n",
        "\ttarget_size=IMG_SIZE,\n",
        "\tbatch_size=BATCH_SIZE,\n",
        "\tclass_mode='binary',\n",
        "\tsubset='validation',\n",
        "\tseed=SEED,\n",
        ")\n",
        "\n",
        "print(\"Classes:\", train_gen.class_indices)\n",
        "steps_per_epoch = train_gen.samples // BATCH_SIZE\n",
        "validation_steps = val_gen.samples // BATCH_SIZE\n",
        "print(\"steps_per_epoch:\", steps_per_epoch, \"validation_steps:\", validation_steps)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,281\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,259,265\u001b[0m (8.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> (5.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,281\u001b[0m (5.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Bangun model MobileNetV2 (transfer learning)\n",
        "base_model = MobileNetV2(\n",
        "\tinput_shape=IMG_SIZE + (3,),\n",
        "\tinclude_top=False,\n",
        "\tweights='imagenet'\n",
        ")\n",
        "base_model.trainable = False  # freeze awal\n",
        "\n",
        "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "\toptimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "\tloss='binary_crossentropy',\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 869ms/step - accuracy: 0.9464 - loss: 0.1480 - val_accuracy: 0.8519 - val_loss: 0.3364 - learning_rate: 3.1250e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.9688 - loss: 0.0799 - val_accuracy: 0.8465 - val_loss: 0.3452 - learning_rate: 3.1250e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 807ms/step - accuracy: 0.9461 - loss: 0.1405 - val_accuracy: 0.8424 - val_loss: 0.3540 - learning_rate: 3.1250e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0527 - val_accuracy: 0.8410 - val_loss: 0.3546 - learning_rate: 1.5625e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 808ms/step - accuracy: 0.9441 - loss: 0.1466 - val_accuracy: 0.8424 - val_loss: 0.3570 - learning_rate: 1.5625e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 130ms/step - accuracy: 0.9375 - loss: 0.1538 - val_accuracy: 0.8438 - val_loss: 0.3515 - learning_rate: 7.8125e-06\n"
          ]
        }
      ],
      "source": [
        "# Training dengan callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "EPOCHS = 20\n",
        "ckpt_path = os.path.join(BASE_DIR, 'checkpoints', 'mobilenetv2_tbc_best.keras')\n",
        "os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "\n",
        "callbacks = [\n",
        "\tEarlyStopping(monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True),\n",
        "\tReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
        "\tModelCheckpoint(ckpt_path, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "\ttrain_gen,\n",
        "\tsteps_per_epoch=steps_per_epoch,\n",
        "\tepochs=EPOCHS,\n",
        "\tvalidation_data=val_gen,\n",
        "\tvalidation_steps=validation_steps,\n",
        "\tcallbacks=callbacks\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 811ms/step\n",
            "Akurasi: 0.7902374670184696\n",
            "Confusion Matrix:\n",
            " [[596  22]\n",
            " [137   3]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.81      0.96      0.88       618\n",
            "tuberculosis       0.12      0.02      0.04       140\n",
            "\n",
            "    accuracy                           0.79       758\n",
            "   macro avg       0.47      0.49      0.46       758\n",
            "weighted avg       0.69      0.79      0.73       758\n",
            "\n",
            "ROC-AUC: 0.49588534442903376\n"
          ]
        }
      ],
      "source": [
        "# Evaluasi dan metrik\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "\n",
        "# Prediksi pada seluruh validation set\n",
        "val_gen.reset()\n",
        "y_true = val_gen.classes\n",
        "# jumlah langkah untuk cover semua sample val\n",
        "val_steps_full = int(np.ceil(val_gen.samples / BATCH_SIZE))\n",
        "preds = model.predict(val_gen, steps=val_steps_full)\n",
        "y_pred_prob = preds.ravel()\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"Akurasi:\", (y_pred == y_true).mean())\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=list(train_gen.class_indices.keys())))\n",
        "try:\n",
        "\tauc = roc_auc_score(y_true, y_pred_prob)\n",
        "\tprint(\"ROC-AUC:\", auc)\n",
        "except Exception as e:\n",
        "\tprint(\"ROC-AUC gagal dihitung:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'normal', 1: 'tuberculosis'}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Prediksi: tuberculosis Prob: 0.5062216520309448\n"
          ]
        }
      ],
      "source": [
        "# Simpan model dan label map + contoh inferensi\n",
        "LABEL_MAP = {v: k for k, v in train_gen.class_indices.items()}\n",
        "print(LABEL_MAP)\n",
        "\n",
        "export_dir = os.path.join(BASE_DIR, 'exports')\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "model_path = os.path.join(export_dir, 'mobilenetv2_tbc.keras')\n",
        "labels_path = os.path.join(export_dir, 'labels.json')\n",
        "\n",
        "model.save(model_path)\n",
        "import json\n",
        "with open(labels_path, 'w') as f:\n",
        "\tjson.dump(LABEL_MAP, f)\n",
        "\n",
        "# Contoh inferensi pada satu gambar\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# ganti ke path gambar uji yang Anda inginkan\n",
        "sample_path = os.path.join(DATA_DIR, 'tuberculosis', os.listdir(os.path.join(DATA_DIR, 'tuberculosis'))[0])\n",
        "img = image.load_img(sample_path, target_size=IMG_SIZE)\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "prob = model.predict(x)[0,0]\n",
        "cls = 1 if prob >= 0.5 else 0\n",
        "print(\"Prediksi:\", LABEL_MAP[cls], \"Prob:\", float(prob))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,281\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,259,265\u001b[0m (8.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,177</span> (6.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,626,177\u001b[0m (6.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">633,088</span> (2.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m633,088\u001b[0m (2.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 921ms/step - accuracy: 0.9407 - loss: 0.1436 - val_accuracy: 0.1929 - val_loss: 5.5426 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/94\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 524ms/step - accuracy: 0.9688 - loss: 0.0703"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ahuma\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 109ms/step - accuracy: 0.9688 - loss: 0.0703 - val_accuracy: 0.2024 - val_loss: 5.4189 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 800ms/step - accuracy: 0.9790 - loss: 0.0613 - val_accuracy: 0.2826 - val_loss: 3.9050 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.2921 - val_loss: 3.7166 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 853ms/step - accuracy: 0.9833 - loss: 0.0423 - val_accuracy: 0.4769 - val_loss: 2.3501 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.4457 - val_loss: 2.5006 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 872ms/step - accuracy: 0.9880 - loss: 0.0328 - val_accuracy: 0.2609 - val_loss: 4.5988 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 0.9688 - loss: 0.0414 - val_accuracy: 0.2609 - val_loss: 4.6293 - learning_rate: 5.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 993ms/step - accuracy: 0.9927 - loss: 0.0218 - val_accuracy: 0.9239 - val_loss: 0.2097 - learning_rate: 5.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9280 - val_loss: 0.2003 - learning_rate: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Fine-tuning: unfreeze sebagian layer MobileNetV2 dan latih lanjut\n",
        "FINE_TUNE_AT = 120  # unfreeze dari layer ke-120 ke atas (sesuaikan)\n",
        "base_model.trainable = True\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "\tlayer.trainable = (i >= FINE_TUNE_AT)\n",
        "\n",
        "model.compile(\n",
        "\toptimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "\tloss='binary_crossentropy',\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "FINE_EPOCHS = 10\n",
        "ft_ckpt_path = os.path.join(BASE_DIR, 'checkpoints', 'mobilenetv2_tbc_finetuned_best.keras')\n",
        "callbacks_ft = [\n",
        "\tEarlyStopping(monitor='val_accuracy', patience=4, mode='max', restore_best_weights=True),\n",
        "\tReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
        "\tModelCheckpoint(ft_ckpt_path, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "]\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "\ttrain_gen,\n",
        "\tsteps_per_epoch=steps_per_epoch,\n",
        "\tepochs=FINE_EPOCHS,\n",
        "\tvalidation_data=val_gen,\n",
        "\tvalidation_steps=validation_steps,\n",
        "\tcallbacks=callbacks_ft\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plot tersimpan di: D:\\SKRIPSI\\DETEKSI TBC\\exports\\plots\n"
          ]
        }
      ],
      "source": [
        "# Plot kurva training dan simpan\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_and_save(history_obj, title_prefix, out_dir):\n",
        "\tos.makedirs(out_dir, exist_ok=True)\n",
        "\thist = history_obj.history\n",
        "\t# Accuracy\n",
        "\tplt.figure()\n",
        "\tplt.plot(hist.get('accuracy', []), label='train_acc')\n",
        "\tplt.plot(hist.get('val_accuracy', []), label='val_acc')\n",
        "\tplt.title(f'{title_prefix} Accuracy')\n",
        "\tplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n",
        "\tplt.tight_layout()\n",
        "\tplt.savefig(os.path.join(out_dir, f'{title_prefix}_accuracy.png'), dpi=150)\n",
        "\tplt.close()\n",
        "\t# Loss\n",
        "\tplt.figure()\n",
        "\tplt.plot(hist.get('loss', []), label='train_loss')\n",
        "\tplt.plot(hist.get('val_loss', []), label='val_loss')\n",
        "\tplt.title(f'{title_prefix} Loss')\n",
        "\tplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "\tplt.tight_layout()\n",
        "\tplt.savefig(os.path.join(out_dir, f'{title_prefix}_loss.png'), dpi=150)\n",
        "\tplt.close()\n",
        "\n",
        "plots_dir = os.path.join(BASE_DIR, 'exports', 'plots')\n",
        "plot_and_save(history, 'baseline', plots_dir)\n",
        "try:\n",
        "\tplot_and_save(fine_tune_history, 'finetune', plots_dir)\n",
        "except NameError:\n",
        "\tpass\n",
        "print('Plot tersimpan di:', plots_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 624ms/step\n",
            "Figur disimpan di: D:\\SKRIPSI\\DETEKSI TBC\\exports\\figures\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Simpan Confusion Matrix dan ROC curve sebagai gambar\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig_dir = os.path.join(BASE_DIR, 'exports', 'figures')\n",
        "os.makedirs(fig_dir, exist_ok=True)\n",
        "\n",
        "# Confusion Matrix\n",
        "y_true = val_gen.classes\n",
        "val_steps_full = int(np.ceil(val_gen.samples / BATCH_SIZE))\n",
        "preds = model.predict(val_gen, steps=val_steps_full)\n",
        "y_pred_prob = preds.ravel()\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "labels = list(train_gen.class_indices.keys())\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "plt.figure(figsize=(4,4))\n",
        "disp.plot(values_format='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(fig_dir, 'confusion_matrix.png'), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ROC curve\n",
        "try:\n",
        "\tfpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "\tauc = roc_auc_score(y_true, y_pred_prob)\n",
        "\tplt.figure()\n",
        "\tplt.plot(fpr, tpr, label=f'ROC AUC = {auc:.3f}')\n",
        "\tplt.plot([0,1], [0,1], 'k--')\n",
        "\tplt.xlabel('False Positive Rate')\n",
        "\tplt.ylabel('True Positive Rate')\n",
        "\tplt.title('ROC Curve')\n",
        "\tplt.legend()\n",
        "\tplt.tight_layout()\n",
        "\tplt.savefig(os.path.join(fig_dir, 'roc_curve.png'), dpi=150)\n",
        "\tplt.close()\n",
        "except Exception as e:\n",
        "\tprint('ROC gagal disimpan:', e)\n",
        "\n",
        "print('Figur disimpan di:', fig_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grad-CAM disimpan di: D:\\SKRIPSI\\DETEKSI TBC\\exports\\visualizations\\gradcam_sample.png\n"
          ]
        }
      ],
      "source": [
        "# Grad-CAM pada satu contoh gambar (self-contained)\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Konfigurasi minimal bila kernel baru\n",
        "try:\n",
        "\tBASE_DIR\n",
        "except NameError:\n",
        "\tBASE_DIR = r\"D:\\SKRIPSI\\DETEKSI TBC\"\n",
        "try:\n",
        "\tIMG_SIZE\n",
        "except NameError:\n",
        "\tIMG_SIZE = (224, 224)\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'DATASET')\n",
        "\n",
        "# Pastikan model tersedia\n",
        "try:\n",
        "\tmodel\n",
        "except NameError:\n",
        "\tmodel_path = os.path.join(BASE_DIR, 'exports', 'mobilenetv2_tbc.keras')\n",
        "\tmodel = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Tentukan path contoh gambar jika belum ada\n",
        "try:\n",
        "\tsample_path\n",
        "except NameError:\n",
        "\tcls_dir = 'tuberculosis' if os.path.isdir(os.path.join(DATA_DIR, 'tuberculosis')) else 'normal'\n",
        "\tsample_path = os.path.join(DATA_DIR, cls_dir, os.listdir(os.path.join(DATA_DIR, cls_dir))[0])\n",
        "\n",
        "last_conv_layer_name = 'Conv_1'  # terakhir conv MobileNetV2\n",
        "\n",
        "# Ambil satu sample\n",
        "img = image.load_img(sample_path, target_size=IMG_SIZE)\n",
        "x = image.img_to_array(img)\n",
        "x_batch = np.expand_dims(x, axis=0)\n",
        "x_batch = preprocess_input(x_batch)\n",
        "\n",
        "# Temukan base model (MobileNetV2) yang ter-embed di dalam model\n",
        "base_in_graph = None\n",
        "for lyr in model.layers:\n",
        "\t# layer model fungsional (nested model) akan punya atribut .layers\n",
        "\tif hasattr(lyr, 'layers') and len(getattr(lyr, 'layers', [])) > 0:\n",
        "\t\tbase_in_graph = lyr\n",
        "\t\tbreak\n",
        "\n",
        "if base_in_graph is None:\n",
        "\traise ValueError('Base feature extractor (MobileNetV2) tidak ditemukan di dalam model.')\n",
        "\n",
        "# Ambil layer konvolusi terakhir dari base model ter-embed\n",
        "try:\n",
        "\tlast_conv_layer = base_in_graph.get_layer(last_conv_layer_name)\n",
        "except ValueError:\n",
        "\tlast_conv_layer_name = 'out_relu'\n",
        "\tlast_conv_layer = base_in_graph.get_layer(last_conv_layer_name)\n",
        "\n",
        "# Bangun model fungsional baru: input = input base, output = [feat target, pred akhir]\n",
        "base_input = base_in_graph.input\n",
        "conv_target = last_conv_layer.output\n",
        "x_head = base_in_graph.output\n",
        "# Rekonstruksi head persis sesuai urutan setelah base model\n",
        "start_idx = [i for i, lyr in enumerate(model.layers) if lyr is base_in_graph][0] + 1\n",
        "for lyr in model.layers[start_idx:]:\n",
        "\tx_head = lyr(x_head)\n",
        "\n",
        "grad_model = tf.keras.models.Model(inputs=base_input, outputs=[conv_target, x_head])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "\tconv_outputs, predictions = grad_model(x_batch, training=False)\n",
        "\t# Untuk binary sigmoid (1 unit), indeks 0 adalah probabilitas kelas positif\n",
        "\tloss = predictions[:, 0]\n",
        "\n",
        "grads = tape.gradient(loss, conv_outputs)\n",
        "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "conv_outputs = conv_outputs[0]\n",
        "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "heatmap = np.maximum(heatmap, 0) / (np.max(heatmap) + 1e-8)\n",
        "\n",
        "# Overlay heatmap ke gambar asli\n",
        "import cv2\n",
        "orig = cv2.cvtColor(cv2.imread(sample_path), cv2.COLOR_BGR2RGB)\n",
        "orig = cv2.resize(orig, IMG_SIZE)\n",
        "heatmap_resized = cv2.resize(heatmap, IMG_SIZE)\n",
        "heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
        "heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)\n",
        "overlay = np.uint8(0.4 * heatmap_color + 0.6 * orig)\n",
        "\n",
        "vis_dir = os.path.join(BASE_DIR, 'exports', 'visualizations')\n",
        "os.makedirs(vis_dir, exist_ok=True)\n",
        "vis_path = os.path.join(vis_dir, 'gradcam_sample.png')\n",
        "cv2.imwrite(vis_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
        "print('Grad-CAM disimpan di:', vis_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
